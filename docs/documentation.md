````markdown
# ğŸ“‘ Burmese Movies Catalogue â€“ Developer Documentation

## ğŸ“Œ Scope

This document supports developers working on the **Burmese Movies Catalogue crawler** by outlining its validation pipeline, mock mode, and test strategy.

It complements the following key documents:

- [`README.md`](../README.md) â€” high-level project vision, features, usage
- [`architecture.md`](architecture.md) â€” current & future system design, diagrams, pain-points
- [`business_requirements.yaml`](business_requirements.yaml) â€” functional goals, constraints, KPIs

---

## ğŸ§ª Pydantic-Based Validation

All scraped items are validated using **Pydantic** before being stored or exported.

### ğŸ“‹ Key Validation Rules

- `title` is required and cannot be blank
- `year` must fall between 1900 and 2100
- `poster_url` and `streaming_link` must be valid URLs
- `cast` must be either a comma-separated string or list of strings
- `synopsis` must be â‰¤ 1000 characters
- Leading/trailing whitespace is stripped from all string fields

### ğŸ“ Schema Location

- **Definition**: `burmese_movies_crawler/schema/item_schema.py`
- **Validation Logic**: `burmese_movies_crawler/pipelines/burmese_pipeline.py`

---

## ğŸ§ª Validation Flow Summary

```text
ğŸ•·ï¸  Crawl (Scrapy Spider)
      â†“
ğŸ§±  Parse HTML Content
      â†“
ğŸ“¦  Build Scrapy Item (BurmeseMoviesItem)
      â†“
âœ…  Pydantic Validation (MovieItem Schema)
    â”œâ”€ Valid â†’ Pass to Pipeline
    â””â”€ Invalid â†’ Drop & Log Warning
      â†“
ğŸ§¹  Transform / Normalize (optional enrichments)
      â†“
ğŸ“  Store in JSON / Database / Export Format
````

---

## ğŸ§ª Unit Testing Coverage

Validation logic is tested under:

```text
tests/unit/test_item_schema.py
```

Includes edge case tests for:

* Empty or malformed fields
* Invalid URLs
* Incorrect data types
* Unicode normalization

Run tests with:

```bash
pytest tests/
```

---

## ğŸ§ª Mock Mode (Offline Testing)

Mock Mode allows you to run the crawler entirely offline, simulating real runs using saved HTML files.

### ğŸ’¡ Why Use It?

* Enables deterministic testing without network/Selenium
* CI-friendly and lightweight
* Useful for debugging extraction and selectors

### â–¶ï¸ How to Enable

```bash
MOCK_MODE=true python run_spider.py
```

### ğŸ“ How It Works

* Replaces all network/Selenium requests with local files
* Matches saved HTML fixtures based on MD5 hash of original URL

### ğŸ· Fixture Naming Convention

```python
import hashlib
print(hashlib.md5("https://example.com".encode()).hexdigest())
```

Save the corresponding file as:

```text
tests/fixtures/<md5_hash>.html
```

---

## ğŸ” Related Files

* `run_spider.py` â€“ Entry point for the crawler
* `tests/fixtures/` â€“ Directory for local HTML test pages
* `tests/unit/` â€“ Pytest unit tests for schema and parsing
* `output/` â€“ Generated results from each run

---

## ğŸ§­ Whatâ€™s Not in This File

* Strategic rationale: see [`README.md`](../README.md)
* Architecture diagrams: see [`architecture.md`](architecture.md)
* System goals & KPIs: see [`requirements_strategy_execution.md`](requirements_strategy_execution.md)

---
